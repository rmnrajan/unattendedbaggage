{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Get Statistics of the video + Download Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FrameDuration :  73.0397063730397 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "file_path =r'C:\\Users\\rmnra\\Downloads\\Abandoned-Object-Detection-master\\Abandoned-Object-Detection-master\\video1.avi'\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(file_path)\n",
    "\n",
    "\n",
    "\n",
    "counter=0\n",
    "while (cap.isOpened()):\n",
    "    # read the frame ; \n",
    "    #Docstring:   read([, image]) -> retval, image\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    \n",
    "    # have to check, else error on the last frame.\n",
    "    if ret==0:\n",
    "        break\n",
    "    \n",
    "    #Create a string FrameNo ; store all the frames in C\\Frames\n",
    "    FrameNo = 'C:/Users/rmnra/Downloads/Abandoned-Object-Detection-master/Abandoned-Object-Detection-master/'+'FrameNo'+str(counter)+'.png'\n",
    "    #Save the frames\n",
    "    cv2.imwrite(FrameNo,frame)\n",
    "    \n",
    "    \n",
    "    counter = counter + 1\n",
    "    \n",
    "    #show the frame\n",
    "    #Docstring:   imshow(winname, mat) -> None\n",
    "    cv2.imshow('Window',frame)\n",
    "    \n",
    "    #control, press 'q' key to exit\n",
    "    # Min cv2.waitKey(integer = min at 1) ; video will be fast ; increase integer value to slow the video    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "#print video statistics ; before release of cap ; else no value\n",
    "\n",
    "#Get duration of the video\n",
    "FrameCount = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "FrameperSecond =cap.get(cv2.CAP_PROP_FPS)\n",
    "DurationSecond = FrameCount/FrameperSecond\n",
    "if FrameperSecond>0:\n",
    "    print (\"FrameDuration : \", DurationSecond, \"seconds\")\n",
    "\n",
    "\n",
    "#when everything is done, release cap\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the mask dimension to hide the train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#pathfile =r'D:\\Jeffrey\\IPython\\1.OpenCV-1\\Videos\\Traffic\\AVVS\\AVSS\\FrameNo88_Train.png'\n",
    "pathfile =r'C:\\Users\\rmnra\\Downloads\\AbandonObject-master\\AbandonObject-master\\FrameNo88_Train.png'\n",
    "#---------------------------------\n",
    "# Load image\n",
    "#---------------------------------\n",
    "img_original = cv2.imread(pathfile)\n",
    "cv2.imshow('original', img_original)\n",
    "\n",
    "#---------------------------------\n",
    "# Draw Markers + Get width and Height  + Break into 10 rows and columns\n",
    "#---------------------------------\n",
    "\n",
    "width = 720 ; \n",
    "height =576\n",
    "# draw for every 50 \n",
    "\n",
    "\n",
    "# Draw columns at 50 intervals, width step at 50, height from 0 to 576\n",
    "col_interval=50\n",
    "for i in range (0,width,col_interval):\n",
    "    cv2.line(img_original,(i,0),(i,height),(255,255,0),2)\n",
    "    cv2.putText(img_original,'%s'%(i), (i,col_interval/2),cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0,0,0),thickness=1) #0.6 is the fontScale\n",
    "cv2.imshow('markers_col',img_original)\n",
    "\n",
    "#Draw rows at 50 interval\n",
    "row_interval=50\n",
    "\n",
    "for i in range(0,height,row_interval):\n",
    "    cv2.line(img_original,(0,i),(width,i),(255,255,0),2)\n",
    "    cv2.putText(img_original,'%s'%(i), (row_interval/2,i),cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0,0,0),thickness=1) #0.6 is the fontScale\n",
    "   \n",
    "cv2.imshow('markers_col_row',img_original)\n",
    "\n",
    "\n",
    "#---------------------------------\n",
    "# Manually read the grid and park down the x, y of the area of interest + Draw the polygon to confirm the mask location\n",
    "#---------------------------------\n",
    "\n",
    "#First mask - which is whole image black\n",
    "mask = np.zeros(img_original.shape[:2], dtype = \"uint8\") # (576, 720, 3), take (576,720) same height and width as the image\n",
    "cv2.imshow('mask',mask) \n",
    "\n",
    "\n",
    "pts = np.array([[280,80],[0,300],[0,500],[700,500],[700,80]], np.int32)\n",
    "\n",
    "#Docstring:   polylines(img, pts, isClosed, color[, thickness[, lineType[, shift]]]) -> None\n",
    "cv2.polylines(img_original,[pts],True,(255,0,0),thickness=2)\n",
    "cv2.imshow('AreaOfInterest',img_original)\n",
    "\n",
    "print (\"Area of Interest :\\n\", pts)\n",
    "\n",
    "# Mask + white (255) + infill at '1'\n",
    "#Docstring:   fillPoly(img, pts, color[, lineType[, shift[, offset]]]) -> None\n",
    "cv2.fillPoly(mask,[pts],255,1)\n",
    "cv2.imshow('Masked',mask)\n",
    "\n",
    "# Bitwise + mask\n",
    "#Docstring:   bitwise_and(src1, src2[, dst[, mask]]) -> dst\n",
    "masked = cv2.bitwise_and(img_original, img_original, mask = mask) # color, \"mask\" command show only the area of the rectangle\n",
    "cv2.imshow('MaskedImg', masked)\n",
    "\n",
    "\n",
    "\n",
    "#---------------------------------\n",
    "# Show all images in Matplotlib\n",
    "#---------------------------------\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,20)) # control size ; width and height in inches\n",
    "plt.subplot(231), plt.imshow(img_original), plt.title('Original'),plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(232), plt.imshow(masked), plt.title('MaskedImg'),plt.xticks([]), plt.yticks([])\n",
    "\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BackgroundSubtractorMOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "pathfile =r'D:\\Jeffrey\\IPython\\1.OpenCV-1\\Videos\\Traffic\\AVVS\\AVSS\\FrameNo88_Train.png'\n",
    "\n",
    "\n",
    "#---------------------------------\n",
    "#size the window first\n",
    "#Docstring:   namedWindow(winname[, flags]) -> None\n",
    "#---------------------------------\n",
    "cv2.namedWindow('CannyEdgeDet',cv2.WINDOW_NORMAL) # user can resize window ; cv2.WINDOW_AUTOSIZE is the default\n",
    "cv2.namedWindow('frame',cv2.WINDOW_NORMAL) # user can resize window ; cv2.WINDOW_AUTOSIZE is the default\n",
    "cv2.namedWindow('Abandoned Object Detection',cv2.WINDOW_NORMAL) # user can resize window ; cv2.WINDOW_AUTOSIZE is the default\n",
    "cv2.namedWindow('frame_masked',cv2.WINDOW_NORMAL) # user can resize window ; cv2.WINDOW_AUTOSIZE is the default\n",
    "cv2.namedWindow('Morph_Close',cv2.WINDOW_NORMAL) # user can resize window ; cv2.WINDOW_AUTOSIZE is the default\n",
    "\n",
    "#---------------------------------\n",
    "# Load image\n",
    "#---------------------------------\n",
    "img_original = cv2.imread(pathfile)\n",
    "cv2.imshow('original', img_original)\n",
    "\n",
    "\n",
    "\n",
    "#---------------------------------\n",
    "# Create Black Mask + Draw White Polygon on Black Mask\n",
    "#---------------------------------\n",
    "\n",
    "#BLACK :First mask - which is whole image black\n",
    "mask = np.zeros(img_original.shape[:2], dtype = \"uint8\") # (576, 720, 3), take (576,720) same height and width as the image\n",
    "#cv2.imshow('mask',mask) \n",
    "\n",
    "# WHITE: Update pts which is the Area of Interest\n",
    "pts = np.array([[280,80],[0,300],[0,500],[650,500],[650,80]], np.int32)\n",
    "\n",
    "# Mask + white (255) + infill at '1'\n",
    "#Docstring:   fillPoly(img, pts, color[, lineType[, shift[, offset]]]) -> None\n",
    "cv2.fillPoly(mask,[pts],255,1)\n",
    "cv2.imshow('Masked',mask)\n",
    "\n",
    "\n",
    "\n",
    "# location of video and first frame\n",
    "file_path =r'D:\\Jeffrey\\IPython\\1.OpenCV-1\\Videos\\Traffic\\AVVS\\AVSS\\AVSS_E2.avi'\n",
    "\n",
    "# Read video\n",
    "cap = cv2.VideoCapture(file_path)\n",
    "\n",
    "#Initialised BackgroundSubtractor\n",
    "fgbg = cv2.BackgroundSubtractorMOG()\n",
    "\n",
    "consecutiveframe=20\n",
    "\n",
    "track_temp=[]\n",
    "track_master=[]\n",
    "track_temp2=[]\n",
    "\n",
    "top_contour_dict = defaultdict(int)\n",
    "obj_detected_dict = defaultdict(int)\n",
    "\n",
    "\n",
    "\n",
    "frameno = 0\n",
    "#counter=1\n",
    "while (cap.isOpened()):\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # have to check, else error on the last frame.\n",
    "    if ret==0:\n",
    "        break\n",
    "    frameno = frameno + 1\n",
    "    cv2.putText(frame,'%s%.f'%('Frameno:',frameno), (400,50),cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255),2)\n",
    "    #--------------------\n",
    "    #Apply Mask on frame\n",
    "    #--------------------\n",
    "    fgmask = fgbg.apply(frame)\n",
    "    fgmask_masked = cv2.bitwise_and(fgmask,fgmask,mask=mask)\n",
    "    \n",
    "        \n",
    "    #-------------------------------------------------------------\n",
    "    #Canny Edge Detection (these are broken lines along the boundary)\n",
    "    #-------------------------------------------------------------\n",
    "    edged = cv2.Canny(fgmask_masked,30,100) #any gradient between 30 and 150 are considered edges\n",
    "    cv2.imshow('CannyEdgeDet',edged)\n",
    "    \n",
    "    \n",
    "    #Docstring:   morphologyEx(src, op, kernel[, dst[, anchor[, iterations[, borderType[, borderValue]]]]]) -> dst\n",
    "    \n",
    "    kernel2 = np.ones((10,10),np.uint8) #higher the kernel, eg (10,10), more will be eroded or dilated\n",
    "    thresh2 = cv2.morphologyEx(fgmask_masked,cv2.MORPH_CLOSE, kernel2,iterations=2)\n",
    "    cv2.imshow('Morph_Close', thresh2)  \n",
    "    \n",
    "    #-------------------------------------------------------------\n",
    "    #Create a copy of the thresh to find contours\n",
    "    #-------------------------------------------------------------\n",
    "    \n",
    "    #(cnts, _) = cv2.findContours(thresh1.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    (cnts, _) = cv2.findContours(thresh2.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    mycnts =[] # every new frame, set to empty list. \n",
    "    # loop over the contours\n",
    "    for c in cnts:\n",
    "\n",
    "\n",
    "        # Calculate Centroid using cv2.moments\n",
    "        M = cv2.moments(c)\n",
    "        if M['m00'] == 0: \n",
    "            pass\n",
    "        else:\n",
    "            cx = int(M['m10']/M['m00'])\n",
    "            cy = int(M['m01']/M['m00'])\n",
    "\n",
    "\n",
    "            #----------------------------------------------------------------\n",
    "            # Set contour criteria\n",
    "            #----------------------------------------------------------------\n",
    "            \n",
    "            if cv2.contourArea(c) < 100 or cv2.contourArea(c)>20000:\n",
    "                pass\n",
    "            else:\n",
    "                mycnts.append(c)\n",
    "                  \n",
    "                # compute the bounding box for the contour, draw it on the frame,\n",
    "                # and update the text\n",
    "                (x, y, w, h) = cv2.boundingRect(c)\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                # putText(img, text, org, fontFace, fontScale, color[, thickness[, lineType[, bottomLeftOrigin]]])\n",
    "                # org ; is the (x,y) location\n",
    "                cv2.putText(frame,'C %s,%s,%.0f'%(cx,cy,cx+cy), (cx,cy),cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0),2) \n",
    "                \n",
    "                \n",
    "                #Store the cx+cy, a single value into a list ; max length of 10000\n",
    "                #Once hit 10000, tranfer top 20 points to dictionary ; empty list\n",
    "                sumcxcy=cx+cy\n",
    "                \n",
    "                \n",
    "                \n",
    "                #track_list.append(cx+cy)\n",
    "                track_temp.append([cx+cy,frameno])\n",
    "                \n",
    "                \n",
    "                track_master.append([cx+cy,frameno])\n",
    "                countuniqueframe = set(j for i, j in track_master) # get a set of unique frameno. then len(countuniqueframe)\n",
    "                \n",
    "                #print len(countuniqueframe), track_master # [sumcxcy,frameno]\n",
    "                \n",
    "                #----------------------------------------------------------------\n",
    "                # Format of track_master\n",
    "                # print 5 [[341, 76], [340, 77], [341, 78], [340, 79], [343, 80]]\n",
    "                #----------------------------------------------------------------\n",
    "                \n",
    "                \n",
    "                #----------------------------------------------------------------\n",
    "                # Store history of frames ; no. of frames stored set by 'consecutiveframe' ;\n",
    "                # if no. of no. of unique frames > consecutiveframes, then 'pop or remove' the earliest frame ; defined by\n",
    "                # minframeno. Objective is to count the same values occurs in all the frames under this list. if yes, \n",
    "                # it is likely that it is a stationary object and not a passing object (walking) \n",
    "                # And the value is stored separately in top_contour_dict , and counted each time. This dict is the master\n",
    "                # dict to store the list of suspecious object. Ideally, it should be a short list. if there is a long list\n",
    "                # there will be many false detection. To keep the list short, increase the 'consecutiveframe'.\n",
    "                # Keep the number of frames to , remove the minframeno.; but hard to remove, rather form a new list without\n",
    "                #the minframeno.\n",
    "                #----------------------------------------------------------------\n",
    "                if len(countuniqueframe)>consecutiveframe: \n",
    "                    minframeno=min(j for i, j in track_master)\n",
    "                    for i, j in track_master:\n",
    "                        if j != minframeno: # get a new list. omit the those with the minframeno\n",
    "                            track_temp2.append([i,j])\n",
    "                \n",
    "                    track_master=list(track_temp2) # transfer to the master list\n",
    "                    track_temp2=[]\n",
    "                    \n",
    "                \n",
    "                #print 'After',track_master\n",
    "                \n",
    "                #count each of the sumcxcy\n",
    "                #if the same sumcxcy occurs in all the frames, store in master contour dictionary, add 1\n",
    "                \n",
    "                countcxcy = Counter(i for i, j in track_master)\n",
    "                #print countcxcy\n",
    "                #example countcxcy : Counter({544: 1, 537: 1, 530: 1, 523: 1, 516: 1})\n",
    "                #if j which is the count occurs in all the frame, store the sumcxcy in dictionary, add 1\n",
    "                for i,j in countcxcy.items(): \n",
    "                    if j>=consecutiveframe:\n",
    "                        top_contour_dict[i] += 1\n",
    "  \n",
    "                \n",
    "                if sumcxcy in top_contour_dict:\n",
    "                    if top_contour_dict[sumcxcy]>100:\n",
    "                        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 3)\n",
    "                        cv2.putText(frame,'%s'%('CheckObject'), (cx,cy),cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255),2)\n",
    "                        print 'Detected : ', sumcxcy,frameno, obj_detected_dict\n",
    "                        \n",
    "                        # Store those objects that are detected, and store the last frame that it happened.\n",
    "                        # Need to find a way to clean the top_contour_dict, else contour will be detected after the \n",
    "                        # object is removed because the value is still in the dict.\n",
    "                        # Method is to record the last frame that the object is detected with the Current Frame (frameno)\n",
    "                        # if Current Frame - Last Frame detected > some big number say 100 x 3, then it means that \n",
    "                        # object may have been removed because it has not been detected for 100x3 frames.\n",
    "                        \n",
    "                        obj_detected_dict[sumcxcy]=frameno\n",
    "\n",
    "    for i, j in obj_detected_dict.items():\n",
    "        if frameno - obj_detected_dict[i]>200:\n",
    "            print 'PopBefore',i, obj_detected_dict[i],frameno,obj_detected_dict\n",
    "            print 'PopBefore : top_contour :',top_contour_dict\n",
    "            obj_detected_dict.pop(i)\n",
    "            \n",
    "            # Set the count for eg 448 to zero. because it has not be 'activated' for 200 frames. Likely, to have been removed.\n",
    "            top_contour_dict[i]=0\n",
    "            print 'PopAfter',i, obj_detected_dict[i],frameno,obj_detected_dict\n",
    "            print 'PopAfter : top_contour :',top_contour_dict\n",
    "\n",
    "                        \n",
    "    \n",
    "    \n",
    "                \n",
    "                 \n",
    "               \n",
    "\n",
    "    \n",
    "    #cv2.putText(frame,'%s%s'%('Objects :',len(mycnts)), (50,50),cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255),2)\n",
    "\n",
    "    #--------------------------------------\n",
    "    #Draw the AreaofInterest on the frame\n",
    "    #--------------------------------------\n",
    "    cv2.polylines(frame,[pts],True,(255,0,0),thickness=2)\n",
    "    \n",
    "    \n",
    "    #--------------------------------------\n",
    "    # Show images\n",
    "    #--------------------------------------\n",
    "        \n",
    "    cv2.imshow('Abandoned Object Detection',frame)\n",
    "    cv2.imshow('frame',fgmask)\n",
    "         \n",
    "    \n",
    "    cv2.imshow('frame_masked',fgmask_masked)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "#---------------------------------------------------\n",
    "#Print out the list of top contours and their count\n",
    "#---------------------------------------------------\n",
    "top_contours = sorted(top_contour_dict,key=top_contour_dict.get,reverse=True) # sort based on highest value, its a list.\n",
    "\n",
    "for i in top_contours:\n",
    "    print i, top_contour_dict[i] #print out the key, count\n",
    "print \"Contours recorded :\",len(top_contours)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_detected_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in top_contour_dict.items():\n",
    "    print i, j\n",
    "print \"--\"\n",
    "print\n",
    "for i, j in obj_detected_dict.items():\n",
    "    print i, j\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "top_contour_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Print key,value in Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_master = [[781, 153], [738, 153], [662, 153], [780, 154], [720, 154], [781, 155], [725, 155], [779, 156], [733, 156]]\n",
    "\n",
    "print track_master\n",
    "countcxcy = Counter(i for i, j in track_master)\n",
    "print countcxcy\n",
    "type(countcxcy)\n",
    "for i,j in countcxcy.items():\n",
    "    print i,j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Additions in dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydict1=dict()\n",
    "mydict1['A']=1\n",
    "print mydict1\n",
    "mydict1['A'] += 1\n",
    "print mydict1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Print List to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileout_path=r'D:\\Jeffrey\\IPython\\1.OpenCV-1\\tempcxcy.txt'\n",
    "\n",
    "fileout = open(fileout_path,'w')\n",
    "\n",
    "for cxcy,frameno in track_temp:\n",
    "    fileout.write('%s;%s\\n'%(cxcy,frameno))\n",
    "\n",
    "fileout.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Get Min / Max of a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainlist=[[100,1],[200,1],[103,2],[100,2],[105,2],[100,3],[109,3],[501,3]]\n",
    "x = min(j for i,j in mainlist)\n",
    "print x\n",
    "y = max(i for i,j in mainlist)\n",
    "print y\n",
    "\n",
    "#Get the number of unique framesets\n",
    "\n",
    "unique = set(j for i,j in mainlist)\n",
    "print unique\n",
    "print len(unique)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Get number of unique values in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all1 = [1,1,2,2,3,3,3,3]\n",
    "unique = set(all1)\n",
    "print unique\n",
    "len(unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Omit a value from the list + create a new list + copy new list to master list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mainlist=[[100,1],[200,1],[103,2],[100,2],[105,2],[100,3],[109,3],[501,3]]\n",
    "newlist=[]\n",
    "print mainlist\n",
    "print len(mainlist)\n",
    "print mainlist[0]\n",
    "print \"mainlist clear :\", mainlist\n",
    "for i,j in mainlist:\n",
    "    print i,j\n",
    "    \n",
    "    if j != 3: #omit 3, use the rest to create a new list\n",
    "        newlist.append([i,j])\n",
    "\n",
    "print 'mainlist', mainlist\n",
    "print 'newlist',newlist\n",
    "print 'transfer to mainlist'\n",
    "mainlist=list(newlist)\n",
    "print 'updated mainlist', mainlist\n",
    "mainlist.append([100,10])\n",
    "print 'mainlist with new items ', mainlist\n",
    "print newlist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 3 mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "mylist = [1,2,3,3,3,3,5,4,5,6,7,7,7,8,8,8,9]\n",
    "data1 = Counter(mylist)\n",
    "print data1 # value : countt\n",
    "len(mylist)\n",
    "#top 3\n",
    "data3=data1.most_common(3)\n",
    "print data3\n",
    "\n",
    "for (i,j) in data3:\n",
    "    print i\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#List to dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#------------------------\n",
    "# List to dictionary\n",
    "#------------------------\n",
    "mylist = [1,2,3,3,3,3,5,4,5,6,7,7,7,8,8,8,9]\n",
    "from collections import defaultdict\n",
    "d = defaultdict(int)\n",
    "\n",
    "for i in mylist:\n",
    "    d[i] +=1\n",
    "    \n",
    "print d\n",
    "len(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Background Subtraction\n",
    "\n",
    "* Read firstframe + BGR2GRAY + Gaussian Blur (ksize must be positive and odd) + show firstframe_blur\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# location of video and first frame\n",
    "file_path =r'D:\\Jeffrey\\IPython\\1.OpenCV-1\\Videos\\Traffic\\AVVS\\AVSS\\AVSS_E2.avi'\n",
    "firstframe_path =r'D:\\Jeffrey\\IPython\\1.OpenCV-1\\Videos\\Traffic\\AVVS\\AVSS\\FrameNo0-AVSS_E2.png'\n",
    "\n",
    "#Read firstframe + BGR2GRAY + Gaussian Blur (ksize must be positive and odd) + show firstframe_blur\n",
    "firstframe = cv2.imread(firstframe_path)\n",
    "firstframe_gray = cv2.cvtColor(firstframe, cv2.COLOR_BGR2GRAY)\n",
    "firstframe_blur = cv2.GaussianBlur(firstframe_gray,(21,21),0)\n",
    "cv2.imshow('Firstframe_blur',firstframe_blur)\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(file_path)\n",
    "\n",
    "counter = 0\n",
    "frameno =0\n",
    "\n",
    "\n",
    "\n",
    "while (cap.isOpened()):\n",
    "    # read the frame ; \n",
    "    #Docstring:   read([, image]) -> retval, image\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    \n",
    "    # have to check, else error on the last frame.\n",
    "    if ret==0:\n",
    "        break\n",
    "    frameno = frameno + 1\n",
    "    \n",
    "    #-------------------------------------------------\n",
    "    #Draw count line\n",
    "    #-------------------------------------------------\n",
    "    \n",
    "    #Height = 400, Width = 600\n",
    "    cv2.line(frame,(100,150),(100,400),(0,255,0),2)\n",
    "    \n",
    "    #-------------------------------------------------\n",
    "    #Frame + BGR2GRAY + Gaussian Blur + show frame_blur\n",
    "    #-------------------------------------------------\n",
    "    \n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame_blur = cv2.GaussianBlur(frame_gray,(21,21),0)\n",
    "    cv2.imshow('frame_blur',frame_blur)\n",
    "    \n",
    "    #Absolute difference between firstframe_blur and frame_blur+ show frame_difference\n",
    "    frame_difference = cv2.absdiff(firstframe_blur, frame_blur)\n",
    "    cv2.imshow('frame_diff',frame_difference)\n",
    "    \n",
    "    #-------------------------------------------------------------\n",
    "    #Canny Edge Detection (these are broken lines along the boundary)\n",
    "    #-------------------------------------------------------------\n",
    "    edged = cv2.Canny(frame_difference,30,100) #any gradient between 30 and 150 are considered edges\n",
    "    cv2.imshow('Edge',edged)\n",
    "    \n",
    "    # Set up kernel for Morphological Transformation\n",
    "    kernel = np.ones((15,15),np.uint8) #higher the kernel, eg (10,10), more will be eroded or dilated\n",
    "    \n",
    "    # Choose either 1 or 2\n",
    "    # Method 1: Dilate the Edges so that we can find contours\n",
    "    thresh1 = cv2.dilate(edged, kernel, iterations=3)\n",
    "    cv2.imshow('Dilate',thresh1)\n",
    "    \n",
    "    # Method 2 : morphologyEx (CLOSED)Dilation followed by Erosion**. \n",
    "    # It is useful in **closing small holes inside the foreground** objects, or small black points on the object.\n",
    "    #Docstring:   morphologyEx(src, op, kernel[, dst[, anchor[, iterations[, borderType[, borderValue]]]]]) -> dst\n",
    "    kernel2 = np.ones((20,20),np.uint8) #higher the kernel, eg (10,10), more will be eroded or dilated\n",
    "    thresh2 = cv2.morphologyEx(edged,cv2.MORPH_CLOSE, kernel2,iterations=2)\n",
    "    cv2.imshow('Morph_Close', thresh2)  \n",
    "    \n",
    "    \n",
    "    #-------------------------------------------------------------\n",
    "    #Create a copy of the thresh to find contours\n",
    "    #-------------------------------------------------------------\n",
    "    \n",
    "    #(cnts, _) = cv2.findContours(thresh1.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    (cnts, _) = cv2.findContours(thresh2.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    #(cnts, _) = cv2.findContours(thresh2.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    #cv2.putText(frame,'P', (100,250),cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0),2)\n",
    "    \n",
    "\n",
    "    mycnts =[] # every new frame, set to empty list. \n",
    "    # loop over the contours\n",
    "    for c in cnts:\n",
    "\n",
    "\n",
    "        # Calculate Centroid using cv2.moments\n",
    "        M = cv2.moments(c)\n",
    "        if M['m00'] == 0: \n",
    "            pass\n",
    "        else:\n",
    "            cx = int(M['m10']/M['m00'])\n",
    "            cy = int(M['m01']/M['m00'])\n",
    "\n",
    "\n",
    "            #----------------------------------------------------------------\n",
    "            # Set contour criteria\n",
    "            #----------------------------------------------------------------\n",
    "            \n",
    "            if cv2.contourArea(c) < 200 or cv2.contourArea(c)>20000:\n",
    "                pass\n",
    "            elif (cv2.contourArea(c)>5000 and cx<70):\n",
    "                pass\n",
    "            else:\n",
    "                mycnts.append(c)\n",
    "                \n",
    "                # compute the bounding box for the contour, draw it on the frame,\n",
    "                # and update the text\n",
    "                (x, y, w, h) = cv2.boundingRect(c)\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                # putText(img, text, org, fontFace, fontScale, color[, thickness[, lineType[, bottomLeftOrigin]]])\n",
    "                # org ; is the (x,y) location\n",
    "                cv2.putText(frame,'C %s,%s'%(cx,cy), (cx,cy),cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0),2)\n",
    "                \n",
    "                print cv2.contourArea(c), cx, cy, frameno\n",
    "                #cv2.putText(frame,'%s,%s'%('Object',len(cnts)), (50,50),cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0),2)\n",
    "                \n",
    "                \n",
    "\n",
    "\n",
    "    cv2.putText(frame,'%s%s'%('Objects :',len(mycnts)), (50,50),cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255),2)\n",
    "\n",
    "\n",
    "    #show the frame\n",
    "    #Docstring:   imshow(winname, mat) -> None\n",
    "    cv2.imshow('Window',frame)\n",
    "    \n",
    "\n",
    "\n",
    "    #control, press 'q' key to exit\n",
    "    # Min cv2.waitKey(integer = min at 1) ; video will be fast ; increase integer value to slow the video    \n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "#when everything is done, release cap\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.fillPoly("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgmask[65:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Tracking of contours across multiple frames\n",
    "\n",
    "* Create a list to store the Previous Cx and Current Cx ; comparecx = [previouscx, currentcx]\n",
    "* if previouscx > width (line at eg 100) and currentcx < width ; then the person has cross the line at 100. Add to counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* OBSERVE the video and see what happens when 1 person cross the line\n",
    "* there will be multiple contours because it happens across multiple frames\n",
    "* what we need is to count the contour that just crossed the line (at width = 100)\n",
    "* So [P,C] ; P = previous cx while C = current cx\n",
    "* P must be >100 ; before the line\n",
    "* C must be <100 ; he has crossed the line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample test\n",
    "mcx=[0,0]\n",
    "print mcx\n",
    "mcx=[0,138]\n",
    "print mcx\n",
    "print mcx[0]>60 and mcx[1]<60\n",
    "mcx.pop(0)\n",
    "print mcx\n",
    "mcx.append(109)\n",
    "print mcx\n",
    "mcx.pop(0)\n",
    "print mcx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Background Substraction + Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18753.5 149 296 1111 -\n",
      "10039.0 112 307 1112 -\n",
      "9684.5 110 308 1113 -\n",
      "10020.5 106 307 1114 -\n",
      "16294.5 140 298 1115 -\n",
      "16359.0 139 298 1116 -\n",
      "9850.0 100 309 1117 -\n",
      "18068.0 127 306 1118 -\n",
      "12340.5 97 322 1119 -\n",
      "Pax  1  -  12340.5\n",
      "12183.0 95 319 1120 -\n",
      "12065.0 93 318 1121 -\n",
      "12103.0 93 318 1122 -\n",
      "11750.0 90 315 1123 -\n",
      "11023.0 87 312 1124 -\n",
      "10719.5 85 310 1125 -\n",
      "10641.0 85 309 1126 -\n",
      "10740.0 84 309 1127 -\n",
      "10762.0 84 309 1128 -\n",
      "10739.0 84 308 1129 -\n",
      "9406.0 82 305 1130 -\n",
      "9175.0 81 304 1131 -\n",
      "10127.5 82 306 1132 -\n",
      "9965.5 82 306 1133 -\n",
      "9959.5 82 305 1134 -\n",
      "8869.5 81 301 1135 -\n",
      "9010.5 81 304 1136 -\n",
      "8736.5 81 301 1137 -\n",
      "8589.0 81 301 1138 -\n",
      "8393.0 82 299 1139 -\n",
      "8612.0 81 302 1140 -\n",
      "8787.5 83 302 1141 -\n",
      "8653.0 83 301 1142 -\n",
      "9806.0 84 306 1143 -\n",
      "9890.0 85 307 1144 -\n",
      "8873.0 83 304 1145 -\n",
      "9846.5 84 307 1146 -\n",
      "8936.5 83 304 1147 -\n",
      "9863.0 84 309 1148 -\n",
      "8995.0 83 305 1149 -\n",
      "9301.5 82 308 1150 -\n",
      "9092.5 83 306 1151 -\n",
      "9111.0 83 306 1152 -\n",
      "8869.5 82 305 1153 -\n",
      "8969.0 82 306 1154 -\n",
      "8900.5 81 305 1155 -\n",
      "9003.0 81 306 1156 -\n",
      "8865.0 82 305 1157 -\n",
      "8978.0 81 306 1158 -\n",
      "9005.5 81 305 1159 -\n",
      "9173.0 81 309 1160 -\n",
      "9368.5 81 309 1161 -\n",
      "9684.5 82 310 1162 -\n",
      "9426.5 80 310 1163 -\n",
      "9470.0 80 310 1164 -\n",
      "9452.5 81 310 1165 -\n",
      "9326.5 81 310 1166 -\n",
      "8815.5 80 308 1167 -\n",
      "9092.0 80 309 1168 -\n",
      "9386.5 81 310 1169 -\n",
      "8281.5 81 311 1170 -\n",
      "7898.0 80 310 1171 -\n",
      "8742.0 80 307 1172 -\n",
      "9427.0 80 311 1173 -\n",
      "9056.5 79 310 1174 -\n",
      "9363.5 80 310 1175 -\n",
      "9006.0 80 309 1176 -\n",
      "8976.5 80 309 1177 -\n",
      "8940.0 80 310 1178 -\n",
      "9002.5 80 309 1179 -\n",
      "8896.5 79 309 1180 -\n",
      "9093.0 80 311 1181 -\n",
      "9170.5 80 311 1182 -\n",
      "8946.5 79 310 1183 -\n",
      "8908.5 79 309 1184 -\n",
      "9209.0 80 311 1185 -\n",
      "9573.0 79 313 1186 -\n",
      "9316.0 80 311 1187 -\n",
      "9343.5 79 311 1188 -\n",
      "9344.5 80 312 1189 -\n",
      "9474.5 80 311 1190 -\n",
      "9477.5 79 310 1191 -\n",
      "9484.0 79 310 1192 -\n",
      "8546.5 79 310 1193 -\n",
      "8579.5 79 310 1194 -\n",
      "9424.0 79 310 1195 -\n",
      "9392.5 79 310 1196 -\n",
      "9394.5 79 310 1197 -\n",
      "9385.5 79 310 1198 -\n",
      "9395.0 79 310 1199 -\n",
      "9407.5 79 310 1200 -\n",
      "9407.5 79 310 1201 -\n",
      "9347.5 79 310 1202 -\n",
      "9396.0 78 310 1203 -\n",
      "9633.0 78 312 1204 -\n",
      "9675.5 78 313 1205 -\n",
      "9454.0 78 312 1206 -\n",
      "9470.0 78 311 1207 -\n",
      "9241.5 78 310 1208 -\n",
      "9290.0 78 311 1209 -\n",
      "9249.0 78 311 1210 -\n",
      "9230.0 78 312 1211 -\n",
      "9252.5 78 311 1212 -\n",
      "9252.0 78 311 1213 -\n",
      "9133.5 78 311 1214 -\n",
      "9372.5 77 314 1215 -\n",
      "9372.5 79 312 1216 -\n",
      "9370.5 79 312 1217 -\n",
      "9370.5 79 312 1218 -\n",
      "9395.5 79 312 1219 -\n",
      "9497.0 78 312 1220 -\n",
      "9203.0 78 312 1221 -\n",
      "8631.0 80 317 1222 -\n",
      "9217.0 78 312 1223 -\n",
      "9355.0 77 312 1224 -\n",
      "9384.0 77 311 1225 -\n",
      "9407.0 77 311 1226 -\n",
      "8219.0 77 311 1227 -\n",
      "9503.5 78 310 1228 -\n",
      "9480.5 78 310 1229 -\n",
      "9559.0 78 310 1230 -\n",
      "9573.0 78 310 1231 -\n",
      "9623.0 78 309 1232 -\n",
      "9522.0 78 310 1233 -\n",
      "9547.5 77 310 1234 -\n",
      "9764.5 78 309 1235 -\n",
      "9708.5 78 309 1236 -\n",
      "9758.5 78 309 1237 -\n",
      "9621.0 78 309 1238 -\n",
      "9624.0 78 309 1239 -\n",
      "9687.0 78 309 1240 -\n",
      "9711.0 78 309 1241 -\n",
      "9648.0 78 308 1242 -\n",
      "9651.0 78 308 1243 -\n",
      "9735.0 78 308 1244 -\n",
      "9765.0 78 308 1245 -\n",
      "9763.0 78 308 1246 -\n",
      "8398.5 77 309 1247 -\n",
      "9815.5 78 308 1248 -\n",
      "9820.0 78 308 1249 -\n",
      "9799.0 78 308 1250 -\n",
      "9735.0 78 309 1251 -\n",
      "9763.5 78 309 1252 -\n",
      "9625.5 78 309 1253 -\n",
      "9609.0 78 310 1254 -\n",
      "9600.5 78 310 1255 -\n",
      "9576.5 78 310 1256 -\n",
      "9566.5 78 310 1257 -\n",
      "9449.5 78 309 1258 -\n",
      "9312.0 78 310 1259 -\n",
      "9278.5 78 310 1260 -\n",
      "9302.5 78 310 1261 -\n",
      "9353.5 78 309 1262 -\n",
      "9213.5 78 311 1263 -\n",
      "9388.5 78 312 1264 -\n",
      "16049.0 114 308 1265 -\n",
      "16625.0 114 310 1266 -\n",
      "16809.5 113 311 1267 -\n",
      "9551.0 79 313 1268 -\n",
      "Pax  2  -  9551.0\n",
      "17081.5 114 311 1269 -\n",
      "16979.5 111 322 1270 -\n",
      "16923.5 111 323 1271 -\n",
      "16982.5 111 322 1272 -\n",
      "16993.0 111 322 1273 -\n",
      "18955.0 116 313 1274 -\n",
      "18569.0 116 311 1275 -\n",
      "18630.5 116 310 1276 -\n",
      "18748.5 116 310 1277 -\n",
      "18745.5 116 310 1278 -\n",
      "18764.5 116 309 1279 -\n",
      "14782.0 108 317 1280 -\n",
      "15723.0 109 318 1281 -\n",
      "15732.0 110 318 1282 -\n",
      "14791.5 110 317 1283 -\n",
      "17549.0 114 309 1284 -\n",
      "17928.5 114 310 1285 -\n",
      "17527.5 115 308 1286 -\n",
      "9564.5 78 311 1287 -\n",
      "Pax  3  -  9564.5\n",
      "9540.0 78 310 1288 -\n",
      "9673.0 78 310 1289 -\n",
      "17531.5 114 309 1290 -\n",
      "17601.5 113 310 1291 -\n",
      "16630.5 113 307 1292 -\n",
      "9622.5 78 312 1293 -\n",
      "Pax  4  -  9622.5\n",
      "16538.5 113 306 1294 -\n",
      "9631.5 78 312 1295 -\n",
      "Pax  5  -  9631.5\n",
      "9622.0 78 312 1296 -\n",
      "9637.5 78 311 1297 -\n",
      "9508.5 78 312 1298 -\n",
      "9384.5 78 311 1299 -\n",
      "9455.0 78 312 1300 -\n",
      "9341.5 78 312 1301 -\n",
      "9215.0 78 312 1302 -\n",
      "9203.0 78 312 1303 -\n",
      "9387.5 78 312 1304 -\n",
      "9293.5 78 312 1305 -\n",
      "9324.0 77 313 1306 -\n",
      "9276.0 77 313 1307 -\n",
      "9182.5 77 312 1308 -\n",
      "9173.0 77 312 1309 -\n",
      "9252.0 77 313 1310 -\n",
      "9235.5 77 312 1311 -\n",
      "9342.0 78 311 1312 -\n",
      "9419.5 77 311 1313 -\n",
      "9317.0 77 311 1314 -\n",
      "9359.5 77 312 1315 -\n",
      "9352.5 77 311 1316 -\n",
      "9288.5 77 311 1317 -\n",
      "9330.0 77 311 1318 -\n",
      "9460.5 77 313 1319 -\n",
      "9516.0 77 312 1320 -\n",
      "9391.0 78 311 1321 -\n",
      "9367.5 78 311 1322 -\n",
      "9637.5 78 312 1323 -\n",
      "9459.0 78 310 1324 -\n",
      "9485.0 78 311 1325 -\n",
      "9500.5 78 310 1326 -\n",
      "9499.5 78 310 1327 -\n",
      "9448.5 78 310 1328 -\n",
      "9522.5 78 310 1329 -\n",
      "9573.0 78 309 1330 -\n",
      "9663.0 78 309 1331 -\n",
      "8392.0 77 310 1332 -\n",
      "8174.5 78 310 1333 -\n",
      "8235.0 78 311 1334 -\n",
      "9796.5 79 309 1335 -\n",
      "9771.0 79 309 1336 -\n",
      "9675.0 78 309 1337 -\n",
      "10177.5 80 305 1338 -\n",
      "10207.5 80 306 1339 -\n",
      "10247.5 80 306 1340 -\n",
      "9674.0 78 310 1341 -\n",
      "11155.5 89 298 1342 -\n",
      "11406.0 90 296 1343 -\n",
      "11989.5 91 295 1344 -\n",
      "11989.5 91 295 1345 -\n",
      "12088.0 92 294 1346 -\n",
      "12677.5 95 289 1347 -\n",
      "12025.0 92 294 1348 -\n",
      "11902.0 94 290 1349 -\n",
      "12390.5 95 290 1350 -\n",
      "12503.0 95 291 1351 -\n",
      "12414.0 94 292 1352 -\n",
      "18079.5 118 303 1353 -\n",
      "18193.5 117 302 1354 -\n",
      "18138.5 117 303 1355 -\n",
      "18706.0 118 305 1356 -\n",
      "18622.5 118 305 1357 -\n",
      "18508.5 116 309 1358 -\n",
      "19078.5 117 307 1359 -\n",
      "17512.0 116 312 1360 -\n",
      "11777.5 89 295 1361 -\n",
      "Pax  6  -  11777.5\n",
      "11170.0 85 301 1362 -\n",
      "11173.0 85 301 1363 -\n",
      "11042.5 87 296 1364 -\n",
      "11866.5 88 295 1365 -\n",
      "11610.5 88 293 1366 -\n",
      "11821.5 88 292 1367 -\n",
      "11841.0 88 290 1368 -\n",
      "11789.5 88 289 1369 -\n",
      "11807.0 88 289 1370 -\n",
      "18094.5 120 303 1371 -\n",
      "11113.5 89 284 1372 -\n",
      "Pax  7  -  11113.5\n",
      "29588.5 123 306 1373 -\n",
      "30257.5 123 308 1374 -\n",
      "30244.5 123 308 1375 -\n",
      "30584.0 123 310 1376 -\n",
      "32037.0 126 316 1377 -\n",
      "20773.5 125 319 1378 -\n",
      "11531.5 83 291 1379 -\n",
      "Pax  8  -  11531.5\n",
      "11609.0 83 294 1380 -\n",
      "11609.0 83 294 1381 -\n",
      "32143.5 128 320 1382 -\n",
      "22544.5 128 323 1383 -\n",
      "22493.0 130 326 1384 -\n",
      "29734.0 136 316 1385 -\n",
      "24556.5 128 326 1386 -\n",
      "24589.5 128 326 1387 -\n",
      "30257.0 136 320 1388 -\n",
      "31647.0 138 324 1389 -\n",
      "28693.0 140 316 1390 -\n",
      "29252.0 139 314 1391 -\n",
      "27751.0 143 316 1392 -\n",
      "27744.5 143 316 1393 -\n",
      "26983.0 145 316 1394 -\n",
      "26703.0 148 317 1395 -\n",
      "26422.0 149 318 1396 -\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# location of video and first frame\n",
    "file_path =r'C:\\Users\\rmnra\\Downloads\\Abandoned-Object-Detection-master\\Abandoned-Object-Detection-master\\video1.avi'\n",
    "#firstframe_path =r'C:\\Users\\rmnra\\Downloads\\AbandonObject-master\\AbandonObject-master\\bg.jpg'\n",
    "firstframe_path = r'C:\\Users\\rmnra\\Downloads\\Abandoned-Object-Detection-master\\Abandoned-Object-Detection-master\\FrameNo0.png'\n",
    "#Read firstframe + BGR2GRAY + Gaussian Blur (ksize must be positive and odd) + show firstframe_blur\n",
    "firstframe = cv2.imread(firstframe_path)\n",
    "firstframe_gray = cv2.cvtColor(firstframe, cv2.COLOR_BGR2GRAY)\n",
    "firstframe_blur = cv2.GaussianBlur(firstframe_gray,(21,21),0)\n",
    "cv2.imshow('Firstframe_blur',firstframe_blur)\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(file_path)\n",
    "\n",
    "counter = 0\n",
    "frameno =0\n",
    "comparecx=[0] # [previous cx, current cx] ; cross the line if the Pcx >100, Ccx<100\n",
    "sumarea=0\n",
    "PaxbyArea=0\n",
    "\n",
    "\n",
    "Height = 200\n",
    "Width = 200\n",
    "\n",
    "while (cap.isOpened()):\n",
    "    # read the frame ; \n",
    "    #Docstring:   read([, image]) -> retval, image\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "        # have to check, else error on the last frame.\n",
    "    if ret==0:\n",
    "        break\n",
    "    frameno = frameno + 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    #----------------------\n",
    "    #Draw count line\n",
    "    #----------------------\n",
    "\n",
    "    #Height = 400, Width = 600\n",
    "    cv2.line(frame,(100,150),(100,400),(0,255,0),2)\n",
    "    #cv2.line(frame,(150,150),(150,400),(0,255,0),2)\n",
    "    \n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    #-------------------------------------------------\n",
    "    #Frame + BGR2GRAY + Gaussian Blur + show frame_blur\n",
    "    #-------------------------------------------------\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame_blur = cv2.GaussianBlur(frame_gray,(21,21),0)\n",
    "    cv2.imshow('frame_blur',frame_blur)\n",
    "    \n",
    "    #Absolute difference between firstframe_blur and frame_blur+ show frame_difference\n",
    "    \n",
    "\n",
    "    frame_difference = cv2.absdiff(firstframe_blur, frame_blur)\n",
    "    cv2.imshow('frame_diff',frame_difference)\n",
    "    \n",
    "    \n",
    "    #----------------------------------------------------------------\n",
    "    #Canny Edge Detection (these are broken lines along the boundary)\n",
    "    #----------------------------------------------------------------\n",
    "    \n",
    "    edged = cv2.Canny(frame_difference,30,50) #any gradient between 30 and 150 are considered edges\n",
    "    cv2.imshow('CannyEdgeDetection',edged)\n",
    "    \n",
    "    # Set up kernel for Morphological Transformation\n",
    "    kernel = np.ones((5,5),np.uint8) #higher the kernel, eg (10,10), more will be eroded or dilated\n",
    "    \n",
    "    # Choose either 1 or 2\n",
    "    # Method 1: Dilate the Edges so that we can find contours\n",
    "    thresh = cv2.dilate(edged, kernel, iterations=3)\n",
    "    cv2.imshow('Dilate',thresh)\n",
    "    \n",
    "    # Method 2 : morphologyEx (CLOSED)Dilation followed by Erosion**. \n",
    "    # It is useful in **closing small holes inside the foreground** objects, or small black points on the object.\n",
    "    #Docstring:   morphologyEx(src, op, kernel[, dst[, anchor[, iterations[, borderType[, borderValue]]]]]) -> dst\n",
    "    kernel2 = np.ones((8,8),np.uint8) #higher the kernel, eg (10,10), more will be eroded or dilated\n",
    "    thresh2 = cv2.morphologyEx(edged,cv2.MORPH_CLOSE, kernel2,iterations=3)\n",
    "    cv2.imshow('Morph_Close', thresh2)  \n",
    "    \n",
    "    \n",
    "    #----------------------------------------------------------------    \n",
    "    #Create a copy of the thresh to find contours + set contour criteria + find contour\n",
    "    #----------------------------------------------------------------\n",
    "    \n",
    "    (cnts, _) = cv2.findContours(thresh2.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    #(cnts, _) = cv2.findContours(thresh2.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    cv2.putText(frame,'%s'%('l'), (100,200),cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0),2)\n",
    "    #cv2.putText(frame,'l', (150,200),cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0),2)\n",
    "    \n",
    "    # loop over the contours\n",
    "    for i, c in enumerate(cnts):\n",
    "        # if the contour is too small, ignore it\n",
    "        \n",
    "        M = cv2.moments(cnts[i])\n",
    "        if M['m00'] == 0: \n",
    "            pass\n",
    "        else:\n",
    "            cx = int(M['m10']/M['m00'])\n",
    "            cy = int(M['m01']/M['m00'])\n",
    "        \n",
    "        #----------------------------------------------------------------\n",
    "        # SET contour criteria\n",
    "        #----------------------------------------------------------------\n",
    "        \n",
    "        if cv2.contourArea(c) > 2000 and cx<150 and cy>150:\n",
    "\n",
    "            # compute the bounding box for the contour, draw it on the frame,\n",
    "            # and update the text\n",
    "            (x, y, w, h) = cv2.boundingRect(c)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "  \n",
    "\n",
    "\n",
    "            # putText(img, text, org, fontFace, fontScale, color[, thickness[, lineType[, bottomLeftOrigin]]])\n",
    "            # org ; is the (x,y) location\n",
    "            cv2.putText(frame,'C %s,%s'%(cx,cy), (cx,cy),cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0),2)\n",
    "            \n",
    "            #OBSERVE the video and see what happens when 1 person cross the line\n",
    "            # there will be multiple contours because it happens across multiple frames\n",
    "            # what we need is to count the contour that just crossed the line (at width = 100)\n",
    "            # So [P,C] ; P = previous cx while C = current cx\n",
    "            # P must be >100 ; before the line\n",
    "            # C must be <100 ; he has crossed the line\n",
    "            \n",
    "            print (cv2.contourArea(c), cx, cy, frameno, \"-\")\n",
    "            \n",
    "            #compare previous and current cx to see if they cross the line\n",
    "            #print \"Cx : \",comparecx\n",
    "            comparecx.append(cx)\n",
    "            if comparecx[0]>100 and comparecx[1]<100 : \n",
    "                counter = counter + 1\n",
    "                sumarea = sumarea + cv2.contourArea(c) # sum the total area\n",
    "                PaxbyArea = sumarea/6500 # calibrate this number to get accuracy\n",
    "                print (\"Pax \",counter, \" - \",cv2.contourArea(c))\n",
    "            comparecx.pop(0)\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "    cv2.putText(frame,'%s'%('ByCountline:'), (10,50),cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0),2)\n",
    "    cv2.putText(frame,'%s'%(counter), (10,80),cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0),2)\n",
    "    \n",
    "    cv2.putText(frame,'%s'%('ByContourArea:'), (350,50),cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0),2)\n",
    "    cv2.putText(frame,'%.2f'%(PaxbyArea), (350,80),cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0),2)\n",
    "\n",
    "\n",
    "\n",
    "    #show the frame\n",
    "    #Docstring:   imshow(winname, mat) -> None\n",
    "    cv2.imshow('Window',frame)\n",
    "\n",
    "\n",
    "\n",
    "    #control, press 'q' key to exit\n",
    "    # Min cv2.waitKey(integer = min at 1) ; video will be fast ; increase integer value to slow the video    \n",
    "    if cv2.waitKey(40) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "#when everything is done, release cap\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#Actual count : 110\n",
    "#ByCountline : 88\n",
    "#ByCoutourArea : 109.75\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumarea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BackgroundSubtractorMOG2\n",
    "\n",
    "* With Shadow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# location of video and first frame\n",
    "file_path =r'C:\\Users\\rmnra\\Downloads\\Abandoned-Object-Detection-master\\Abandoned-Object-Detection-master\\video1.avi'\n",
    "\n",
    "cap = cv2.VideoCapture(file_path)\n",
    "\n",
    "fgbg = cv2.BackgroundSubtractorMOG2()\n",
    "\n",
    "while(1):\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    fgmask = fgbg.apply(frame)\n",
    "\n",
    "    cv2.imshow('frame',fgmask)\n",
    "    if cv2.waitKey(40) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need OpenCV 3.0 to have cv2.BackgroundSubtractorGMG() \n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "file_path =r'C:\\Users\\rmnra\\Downloads\\Abandoned-Object-Detection-master\\Abandoned-Object-Detection-master\\video1.avi'\n",
    "\n",
    "cap = cv2.VideoCapture(file_path)\n",
    "\n",
    "\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3))\n",
    "#fgbg = cv2.BackgroundSubtractorGMG()\n",
    "fgbg = cv2.BackgroundSubtractorMOG2()\n",
    "\n",
    "while(1):\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    fgmask = fgbg.apply(frame)\n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    cv2.imshow('frame',fgmask)\n",
    "    if cv2.waitKey(40) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cv2 import __version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
